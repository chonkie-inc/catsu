---
title: list_models() Method
description: Discover available models and their capabilities
icon: List
---

The `list_models()` method returns information about available embedding models.

## Signature

```python
def list_models(
    self,
    provider: Optional[str] = None
) -> List[ModelInfo]
```

## Parameters

### `provider` (str, optional)

Filter models by provider:

```python
# All models from all providers
all_models = client.list_models()

# Only OpenAI models
openai_models = client.list_models("openai")

# Only Voyage AI models
voyage_models = client.list_models("voyageai")
```

## Return Value

Returns a list of `ModelInfo` objects with model metadata:

```python
class ModelInfo:
    name: str                      # Model identifier
    provider: str                  # Provider name
    dimensions: int                # Default embedding dimensions
    max_input_tokens: int          # Maximum tokens per request
    cost_per_million_tokens: float # Cost per million tokens
```

Note: For complete model information including benchmarks, visit [catsu.dev](https://catsu.dev).

## Examples

### List All Models

```python
from catsu import Client

client = Client()
models = client.list_models()

print(f"Total models: {len(models)}")

# Group by provider
providers = {}
for model in models:
    if model.provider not in providers:
        providers[model.provider] = []
    providers[model.provider].append(model.name)

for provider, model_names in providers.items():
    print(f"{provider}: {len(model_names)} models")
```

### Filter by Provider

```python
# Get all OpenAI models
openai_models = client.list_models("openai")

for model in openai_models:
    print(f"{model.name}: {model.dimensions}d, ${model.cost_per_million_tokens}/M tokens")
```

### Find High-Dimensional Models

```python
# Find models with more than 1024 dimensions
high_dim_models = [
    model for model in client.list_models()
    if model.dimensions > 1024
]

print(f"Models with >1024 dimensions: {len(high_dim_models)}")
for model in high_dim_models:
    print(f"  {model.provider}:{model.name} - {model.dimensions}d")
```

## Provider Names

Valid provider filter values:
- `"openai"` - OpenAI
- `"voyageai"` - Voyage AI
- `"cohere"` - Cohere
- `"gemini"` - Google Gemini
- `"jinaai"` - Jina AI
- `"mistral"` - Mistral AI
- `"nomic"` - Nomic
- `"cloudflare"` - Cloudflare Workers AI
- `"deepinfra"` - DeepInfra
- `"mixedbread"` - Mixedbread
- `"togetherai"` - Together AI

## Next Steps

- [Providers](/providers) - Explore all supported providers
- [Best Practices: Model Selection](/best-practices/model-selection) - Choose the right model for your use case
